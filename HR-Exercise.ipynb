{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HR Dataset - Statistics Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data\n",
    "\n",
    "The data set we will use for this exercise comes from a Kaggle challenge and is often used for predictive analytics, namely to predict why the best and most experienced employees tend to leave the company.  We won't be using it for any predictive purposes here, but will instead use this data set to review many of the concepts explored in the Statistical Inference lectures.\n",
    "\n",
    "This data contains fields for various measures of employee performance and reported satisfaction levels, as well as categorical variables for events and salary level.  For now, just explore the data a bit to get a general idea of what is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability, Expectation Values, and Variance\n",
    "\n",
    "The concepts of probability, expectation values, and variance are the bedrock of statistical inference.  Let's begin by employing these concepts to see if we can find interesting paths to go down which may provide insight into the inner workings of this company.\n",
    "\n",
    "1. What is the probability that a randomly selected employee left the company?  What about experienced a work accident?  Also, compute the probability that a randomly selected employee left the company and experienced a work accident.\n",
    "1. Compute the 25th, 50th, and 90th percentiles for the satisfaction level score for all employees that left the company.  Compare these results to the same percentiles for those that did not leave.  What can you say about the results?\n",
    "1. Compute the variance and standard deviation of hours worked.\n",
    "1. Compare the variance between the satisfaction levels of employees who left versus those who stayed.  Which is larger?  What does this mean?\n",
    "1. Compute the mean satisfaction level for each salary category.  Comment on your results.\n",
    "1. Given an employees salary level (low, medium, or high), calculate the probability that they worked more than two standard deviations of the average monthly hours across all groups.  In other words, compute\n",
    "$$P(hours > 2\\sigma \\vert salary ) = \\dfrac{P(salary \\vert hours > 2\\sigma) P(hours > 2\\sigma)}{P(salary)}$$\n",
    "1. What can you say about your results in part 6?\n",
    "1. Repeat parts 6 and 7 for \n",
    "$$P(left \\vert salary ) = \\dfrac{P(salary \\vert left) P(left)}{P(salary)}$$\n",
    "1. What is the odds ratio of an employee with a high salary getting a promotion within the past five years versus a low salary employee?  Comment on your results.\n",
    "1. Suppose we were to pull 50 random samples of employee satisfaction levels.  What would approximately be the mean of this sample?  What would be the mean of, say, 10 sets of random samples?  Demonstrate your assertions by writing Python code to do just that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Distributions and The Central Limit Theorem\n",
    "### The Bernoulli Distribution\n",
    "Bernoulli distributions are the result of a random variable with a binary outcome, like a coin clip or medical test giving a positive or negative result.  Typically, we represent the outcomes of a Bernoulli Random variable $X$ of only taking values of 0 or 1, with probabilities $p$ and $1 - p$ respectively, mean $p$, variance $p(1 - p)$, and PMF given by \n",
    "$$ P(X = x) = p^x (1 - p)^{1 - x} $$\n",
    "Bernoulli random variables crop up very often in statistical analysis, most often in the form of Binomial trials, or, as a sum of independent Bernoulli variables with PMF given by \n",
    "$$ P(X = x) = {n \\choose x} p^x (1 - p)^{n - x} $$\n",
    "where\n",
    "$$ {n \\choose x} = \\frac{n!}{x!(n - x)!} $$\n",
    "In this exercise you'll take a look at the HR data and apply these concepts to gain insight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the HR data, answer the following.\n",
    "1. Which variables in the HR data can be said to be Bernoulli random variables?\n",
    "2. For the k variables you identified in part 1, compute the probabilities $p_k$, of each having a positive $(x = 1)$ result.\n",
    "3. Compute the variance of each of the variables in part 2 using $p_k$ as described above.\n",
    "4. For each of the k variables, compute the probability of randomly selecting exactly 3500 employees with a positive result.  Comment on your answer.\n",
    "5. For each of the k variables, compute the probability of randomly selecting at 3500 **or less** with a positive result.  Comment on your answer.\n",
    "6. Now plot both the PMF and CDF as a function of the number of drawn samples for each of the k variables.  Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Normal Distribution\n",
    "The Normal distribution (or sometimes called the Bell Curve or Guassian) is by far the most prevalent and useful distribution in any field that utilizes statistical techniques.  In fact, it can be shown that the means of random variables sampled from **any** distribution eventually form a normal given a sufficiently large sample size.\n",
    "\n",
    "A normal distribution is characterized by the PDF given by\n",
    "$$p(x|\\mu,\\sigma) = \\frac{1}{\\sqrt{(2\\pi\\sigma^2)}}e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mu$ is the mean and $\\sigma^2$ is the variance, thus the distribution is characterized by mean and variance alone.  In this exercise, you'll examine variables in the HR dataset and construct normals approximating them.\n",
    "\n",
    "Using the HR data, answer the following\n",
    "\n",
    "1. Which variables may be approximately normal?\n",
    "1. For the variables in part 1, plot histograms.\n",
    "1. Compute the mean and variance for each of the variables used in parts 1 and 2.\n",
    "1. Using the mean and variance in part 3, construct normal distributions for each and overlay them on top of the histograms you made in part 1.  Are they well approximated by normals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Poisson Distribution\n",
    "The Poisson distribution is very versatile but is typically used to model counts, such as, the amount of clicks per advertisement and arriving flights per unit time.  It has a PDF given by\n",
    "$$ P(X = x, \\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!} $$\n",
    "where the mean and variance are both equal to $\\lambda$\n",
    "\n",
    "Using the HR data, answer the following.\n",
    "\n",
    "1. What variables would be good candidates for modeling with a Poisson distribution?\n",
    "1. For each variable in part 1, divide each by salary and fit a Poisson distribution to each.\n",
    "1. Compute the probability of obtaining at least the mean of all salary levels in each category by using the Poisson distributions you constructed in part 2.  Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Central Limit Theorem\n",
    "The Central Limit Theorem is perhaps one of the most remarkable results in statistics and mathematics in general.  In short, it says that the distribution of means of independent random variables, sampled from **any** distribution, tends to approach a normal distribution as the sample size increases.\n",
    "\n",
    "An example of this would be taking a pair of dice, rolling them, and recording the mean of each result.  The Central Limit Theorem states, that after enough rolls, the distribution of the means will be approximately normal.  Stated formally, the result is\n",
    "    $$ \\bar{X_n} \\approx N(\\mu, \\sigma^2/n) = \\frac{\\bar{X_n} - \\mu}{\\sigma \\sqrt{n}}$$\n",
    "In this exercise, you'll conduct simulation experiments to explore this idea.\n",
    "\n",
    "Using the HR data, answer the following.\n",
    "1. Choose two variables which may be good candidates to test this theorem.\n",
    "1. Using the variables chosen in part 1, randomly select a set of `n = 10` samples and take the mean.  Repeat this 1000 times for each variable.\n",
    "1. Plot a histogram for each variable used in part 2.  Comment on your results.\n",
    "1. Repeat parts 2-3 for `n = 100`, `n = 500`, and `n = 1000`.  Comment on your results.\n",
    "1. Overlay a normal curve on your `n = 1000` plots, using the mean and variance computed from the data.  Comment on your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "Hypothesis testing is essentially using the data to answer questions of interest.  For example, does a new medication provide any benefit over placebo?  Or is a subset of the population disproportionately more susceptible to a particular disease?  Or is the difference between two companies profits' significant or due to chance alone?\n",
    "\n",
    "Before doing some hypothesis testing on the HR data, recall that hypothesis typically come in pairs of the form $H_0$, called the null hypothesis, versus $H_a$, called the alternative hypothesis.  The null hypothesis represents the \"default\" assumption -- that a medication has no effect for example, while the alternative hypothesis represents what we are looking to discover, in the medication case, whether it provides a significant benefit.  Another common case is testing the difference between two means.  Here, the null hypothesis is that there is no difference between two population means, whereas the alternative hypothesis is that there is a difference.  Stated more precisely\n",
    "$$H_0: \\mu_1 - \\mu_2 = 0$$\n",
    "$$H_a: \\mu_1 - \\mu_2 \\ne 0$$\n",
    "\n",
    "Hypotheses are usually tested by constructing a confidence interval around the test statistic and selecting a \"cut-off\" significance level denoted $\\alpha$.  A typical $\\alpha$ significance is 0.05.  If a test produces a P-value of $\\alpha$ or below, then the null hypothesis can be rejected, strengthening the case of the alternative hypothesis.  It is very important to remember that hypothesis testing can only tell you if your hypothesis is statistically significant -- this does **not** mean that your result may be scientifically significant which requires much more evidence.\n",
    "\n",
    "In this exercise, you'll explore the HR data more and test some hypotheses.\n",
    "\n",
    "Using the HR data, answer the following.\n",
    "\n",
    "1. Compute a confidence interval for satisfaction levels, at the 95% level, of employees who left the company and those who didn't.  Do this using both a t distribution and a normal.  Comment on your results.\n",
    "1. Use a t-test to test the hypothesis that employees who left the company, had lower satisfaction levels than those who did not.  If significant, are the means different?  Comment on your results.  (Hint: Do the two populations have equal variance?)\n",
    "1. Fit a normal curve to each group in part 2 and put them on the same plot next to each other.  Comment on your results.\n",
    "1. Test the hypothesis that the satisfaction level between each salary group, denoted by k, differs signicantly from the mean.  Namely\n",
    "    - $H_0: \\mu - \\mu_k = 0$\n",
    "    - $H_a: \\mu - \\mu_k \\ne 0$\n",
    "1. How would you interpret your results in part 5?\n",
    "1. Generate plots for part 5 as you did in part 3.  What conclusions can you draw from the plot?\n",
    "1. Repeat parts 4-6 on a hypothesis of your choosing.\n",
    "1. Recall that Power is the probability of failing to reject the null hypothesis when it is false (thus more power is good).  Compute the power for the hypothesis that the satisfaction level of high paid employees is different than that of medium paid employees using a t distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "Bootstrapping is an immensely useful technique in practice.  Very often you may find yourself in a situation where you want to compute a statistic, but lack sufficient data to do so.  Bootstrapping works as a remedy to this problem.\n",
    "\n",
    "Recall that the bootstrapping algorithm breaks down as follows:\n",
    "1. Sample n observations with replacement from the observed data resulting in one simulated complete data set. \n",
    "1. Take the statistic of the simulated data set\n",
    "1. Repeat these two steps B times, resulting in B simulated statistics\n",
    "1. These statistics are approximately drawn from the sampling distribution of the statistic of n observations\n",
    "\n",
    "In this exercise, you will implement this algorithm on the HR data.\n",
    "\n",
    "Write a function that can perform boostrapping for the median of a set of n samples in the HR data set.  Test this function on the `satisfaction_level` with `n = 100` and `b = 100` and compare your results to the true median.  Also compute the standard deviation of the bootstrapped median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
